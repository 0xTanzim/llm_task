# FastAPI LangChain REST Service ðŸš€

A professional FastAPI REST service with LangChain integration featuring:
- âœ… **Streaming chat** with real-time tokens
- âœ… **Chain-of-thought reasoning** with structured JSON
- âœ… **OpenAI compatibility** with Google Gemini

## ðŸ“ Project Structure

```
src/
â”œâ”€â”€ main.py              # FastAPI app
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ router.py        # Main router
â”‚   â””â”€â”€ chat.py          # All chat endpoints
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py        # Settings from .env
â””â”€â”€ services/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ llm.py           # LangChain service
```

## ðŸš€ Quick Start

### 1. Setup
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 2. Configure
```bash
cp .env.example .env
# Add your GOOGLE_API_KEY to .env
```

### 3. Run
```bash
cd src
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Access: http://localhost:8000/docs

## ðŸ“¡ API Endpoints

### 1ï¸âƒ£ Chat (Simple & Streaming)
```bash
# Regular chat
curl -X POST "http://localhost:8000/api/chat/" \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello!", "stream": false}'

# Streaming (use -N flag!)
curl -N -X POST "http://localhost:8000/api/chat/" \
  -H "Content-Type: application/json" \
  -d '{"message": "Count to 5", "stream": true}'
```

### 2ï¸âƒ£ Chain-of-Thought Reasoning
```bash
# Streaming
curl -N -X POST "http://localhost:8000/api/chat/reason" \
  -H "Content-Type: application/json" \
  -d '{"query": "What is 2 + 3 * 5?", "stream": true}'

# JSON response
curl -X POST "http://localhost:8000/api/chat/reason" \
  -H "Content-Type: application/json" \
  -d '{"query": "Solve x^2 - 5x + 6 = 0", "stream": false}'
```

Returns structured JSON:
```json
{
  "thinking": "reasoning steps...",
  "steps": ["step1", "step2"],
  "answer": "final answer"
}
```

### Health Check
```bash
curl http://localhost:8000/api/health
```

## ðŸ§ª Streaming Tips

### âš ï¸ Use `-N` flag for real-time streaming!

```bash
# âŒ Waits for complete response
curl -X POST "http://localhost:8000/api/chat/" \
  -d '{"message": "Hello", "stream": true}'

# âœ… Shows real-time tokens
curl -N -X POST "http://localhost:8000/api/chat/" \
  -d '{"message": "Hello", "stream": true}'
```

### JavaScript Client
```javascript
async function streamChat(message) {
  const response = await fetch('http://localhost:8000/api/chat/', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ message, stream: true })
  });

  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    const text = decoder.decode(value);
    text.split('\n').forEach(line => {
      if (line.startsWith('data: ')) console.log(line.slice(6));
    });
  }
}
```

## ðŸ“¦ Tech Stack

| Component | Technology |
|-----------|------------|
| **Framework** | FastAPI |
| **LLM** | LangChain + Google Gemini |
| **Streaming** | Server-Sent Events (SSE) |
| **Validation** | Pydantic |
| **Config** | Python dotenv |

## ðŸŽ“ Features

âœ… REST API Design  
âœ… Async Programming  
âœ… Data Streaming (SSE)  
âœ… LangChain Integration  
âœ… Type Safety (Pydantic)  
âœ… Environment Config  
âœ… Chain-of-Thought Reasoning
