# ===================================
# LangChain FastAPI Agent Configuration
# ===================================

# === LLM Provider (OpenRouter) ===
# Get your API key at: https://openrouter.ai/keys
# OpenRouter provides access to multiple LLM providers
OPENROUTER_API_KEY=sk-or-v1-your-key-here

# Default model (recommended: fast + cost-effective)
DEFAULT_MODEL=google/gemini-2.5-flash-lite-preview-09-2025

# Alternative models you can try:
# - google/gemini-2.5-flash
# - anthropic/claude-3.5-sonnet
# - openai/gpt-4-turbo
# - meta-llama/llama-3.1-70b-instruct

# === Web Search Tool (Tavily) ===
# Get your API key at: https://tavily.com
# Free tier: 1,000 searches/month
TAVILY_API_KEY=tvly-your-key-here

# === PostgreSQL Database ===
# These values must match docker-compose.yml
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres123
POSTGRES_DB=langchain_db
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# Full connection string (used by the app)
DATABASE_URL=postgresql+asyncpg://postgres:postgres123@localhost:5432/langchain_db

# === FastAPI Server ===
API_HOST=0.0.0.0
API_PORT=8000

# Debug mode (set to False in production)
DEBUG=True

# === LangSmith (Optional - for debugging/monitoring) ===
# Get your API key at: https://smith.langchain.com/
# Uncomment to enable tracing
# LANGSMITH_TRACING=true
# LANGSMITH_API_KEY=your-langsmith-key-here
# LANGSMITH_PROJECT=agent_project

# ===================================
# Environment Setup Instructions
# ===================================
#
# 1. Copy this file:
#    cp .env.example .env
#
# 2. Get API Keys:
#    - OpenRouter: https://openrouter.ai/keys (free trial available)
#    - Tavily: https://tavily.com (free tier: 1k searches/month)
#
# 3. Start Database:
#    docker-compose up -d
#
# 4. Run Server:
#    uv run python src/main.py
#
# 5. Test:
#    curl http://localhost:8000/health
#

